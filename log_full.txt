
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python --version
Python 3.13.9

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python -m pip install --upgrade pip
Requirement already satisfied: pip in c:\python\openvino_venv\lib\site-packages (25.3)

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>pip list
Package Version
------- -------
pip     25.3

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>dir
 Volume in drive C is InstallTo
 Volume Serial Number is 76DF-BB22

 Directory of C:\Github\paraformer-zh-ovep-python-static

11/21/2025  11:45 AM    <DIR>          .
11/20/2025  04:20 PM    <DIR>          ..
11/21/2025  11:32 AM           179,712 0.wav
11/21/2025  11:32 AM           165,042 1.wav
11/21/2025  11:32 AM           144,922 2.wav
11/21/2025  11:44 AM            11,203 am.mvn
11/21/2025  11:44 AM             2,509 config.yaml
11/21/2025  11:44 AM               472 configuration.json
11/21/2025  11:32 AM             1,169 export_decoder_onnx.py
11/21/2025  11:32 AM             5,189 export_encoder_onnx.py
11/21/2025  11:32 AM             1,510 export_predictor_onnx.py
11/21/2025  11:45 AM       880,502,012 model.pt
11/21/2025  11:32 AM             6,446 README.md
11/21/2025  11:32 AM               120 requirements.txt
11/21/2025  11:45 AM         8,287,834 seg_dict
11/21/2025  11:32 AM            10,969 test_onnx.py
11/21/2025  11:45 AM            93,676 tokens.json
11/21/2025  11:32 AM            44,688 torch_model.py
              16 File(s)    889,457,473 bytes
               2 Dir(s)  228,858,630,144 bytes free

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>pip install -r requirements.txt
Collecting onnx (from -r requirements.txt (line 1))
  Using cached onnx-1.20.0-cp312-abi3-win_amd64.whl.metadata (8.6 kB)
Collecting torch==2.8.0 (from -r requirements.txt (line 2))
  Using cached torch-2.8.0-cp313-cp313-win_amd64.whl.metadata (30 kB)
Collecting pyyaml (from -r requirements.txt (line 3))
  Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl.metadata (2.4 kB)
Collecting kaldi_native_fbank (from -r requirements.txt (line 4))
  Using cached kaldi_native_fbank-1.22.3-cp313-cp313-win_amd64.whl.metadata (3.4 kB)
Collecting librosa (from -r requirements.txt (line 5))
  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)
Collecting onnxruntime-openvino~=1.23.0 (from -r requirements.txt (line 6))
  Using cached onnxruntime_openvino-1.23.0-cp313-cp313-win_amd64.whl.metadata (5.1 kB)
Collecting openvino~=2025.3.0 (from -r requirements.txt (line 7))
  Using cached openvino-2025.3.0-19807-cp313-cp313-win_amd64.whl.metadata (13 kB)
Collecting filelock (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached filelock-3.20.0-py3-none-any.whl.metadata (2.1 kB)
Collecting typing-extensions>=4.10.0 (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)
Collecting sympy>=1.13.3 (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)
Collecting networkx (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached networkx-3.6-py3-none-any.whl.metadata (6.8 kB)
Collecting jinja2 (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)
Collecting fsspec (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached fsspec-2025.10.0-py3-none-any.whl.metadata (10 kB)
Collecting setuptools (from torch==2.8.0->-r requirements.txt (line 2))
  Using cached setuptools-80.9.0-py3-none-any.whl.metadata (6.6 kB)
Collecting coloredlogs (from onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)
Collecting flatbuffers (from onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)
Collecting numpy>=1.21.6 (from onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached numpy-2.3.5-cp313-cp313-win_amd64.whl.metadata (60 kB)
Collecting packaging (from onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached packaging-25.0-py3-none-any.whl.metadata (3.3 kB)
Collecting protobuf (from onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)
Collecting numpy>=1.21.6 (from onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached numpy-2.2.6-cp313-cp313-win_amd64.whl.metadata (60 kB)
Collecting openvino-telemetry>=2023.2.1 (from openvino~=2025.3.0->-r requirements.txt (line 7))
  Using cached openvino_telemetry-2025.2.0-py3-none-any.whl.metadata (2.3 kB)
Collecting ml_dtypes>=0.5.0 (from onnx->-r requirements.txt (line 1))
  Using cached ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl.metadata (9.2 kB)
Collecting audioread>=2.1.9 (from librosa->-r requirements.txt (line 5))
  Using cached audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)
Collecting numba>=0.51.0 (from librosa->-r requirements.txt (line 5))
  Using cached numba-0.62.1-cp313-cp313-win_amd64.whl.metadata (2.9 kB)
Collecting scipy>=1.6.0 (from librosa->-r requirements.txt (line 5))
  Using cached scipy-1.16.3-cp313-cp313-win_amd64.whl.metadata (60 kB)
Collecting scikit-learn>=1.1.0 (from librosa->-r requirements.txt (line 5))
  Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl.metadata (11 kB)
Collecting joblib>=1.0 (from librosa->-r requirements.txt (line 5))
  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)
Collecting decorator>=4.3.0 (from librosa->-r requirements.txt (line 5))
  Using cached decorator-5.2.1-py3-none-any.whl.metadata (3.9 kB)
Collecting soundfile>=0.12.1 (from librosa->-r requirements.txt (line 5))
  Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl.metadata (16 kB)
Collecting pooch>=1.1 (from librosa->-r requirements.txt (line 5))
  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)
Collecting soxr>=0.3.2 (from librosa->-r requirements.txt (line 5))
  Using cached soxr-1.0.0-cp312-abi3-win_amd64.whl.metadata (5.6 kB)
Collecting lazy_loader>=0.1 (from librosa->-r requirements.txt (line 5))
  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)
Collecting msgpack>=1.0 (from librosa->-r requirements.txt (line 5))
  Using cached msgpack-1.1.2-cp313-cp313-win_amd64.whl.metadata (8.4 kB)
Collecting standard-aifc (from librosa->-r requirements.txt (line 5))
  Using cached standard_aifc-3.13.0-py3-none-any.whl.metadata (969 bytes)
Collecting standard-sunau (from librosa->-r requirements.txt (line 5))
  Using cached standard_sunau-3.13.0-py3-none-any.whl.metadata (914 bytes)
Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa->-r requirements.txt (line 5))
  Using cached llvmlite-0.45.1-cp313-cp313-win_amd64.whl.metadata (5.0 kB)
Collecting platformdirs>=2.5.0 (from pooch>=1.1->librosa->-r requirements.txt (line 5))
  Using cached platformdirs-4.5.0-py3-none-any.whl.metadata (12 kB)
Collecting requests>=2.19.0 (from pooch>=1.1->librosa->-r requirements.txt (line 5))
  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)
Collecting charset_normalizer<4,>=2 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 5))
  Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl.metadata (38 kB)
Collecting idna<4,>=2.5 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 5))
  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)
Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 5))
  Using cached urllib3-2.5.0-py3-none-any.whl.metadata (6.5 kB)
Collecting certifi>=2017.4.17 (from requests>=2.19.0->pooch>=1.1->librosa->-r requirements.txt (line 5))
  Using cached certifi-2025.11.12-py3-none-any.whl.metadata (2.5 kB)
Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa->-r requirements.txt (line 5))
  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)
Collecting cffi>=1.0 (from soundfile>=0.12.1->librosa->-r requirements.txt (line 5))
  Using cached cffi-2.0.0-cp313-cp313-win_amd64.whl.metadata (2.6 kB)
Collecting pycparser (from cffi>=1.0->soundfile>=0.12.1->librosa->-r requirements.txt (line 5))
  Using cached pycparser-2.23-py3-none-any.whl.metadata (993 bytes)
Collecting mpmath<1.4,>=1.1.0 (from sympy>=1.13.3->torch==2.8.0->-r requirements.txt (line 2))
  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)
Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)
Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->onnxruntime-openvino~=1.23.0->-r requirements.txt (line 6))
  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)
Collecting MarkupSafe>=2.0 (from jinja2->torch==2.8.0->-r requirements.txt (line 2))
  Using cached markupsafe-3.0.3-cp313-cp313-win_amd64.whl.metadata (2.8 kB)
Collecting standard-chunk (from standard-aifc->librosa->-r requirements.txt (line 5))
  Using cached standard_chunk-3.13.0-py3-none-any.whl.metadata (860 bytes)
Collecting audioop-lts (from standard-aifc->librosa->-r requirements.txt (line 5))
  Using cached audioop_lts-0.2.2-cp313-abi3-win_amd64.whl.metadata (2.0 kB)
Using cached torch-2.8.0-cp313-cp313-win_amd64.whl (241.3 MB)
Using cached onnxruntime_openvino-1.23.0-cp313-cp313-win_amd64.whl (13.1 MB)
Using cached openvino-2025.3.0-19807-cp313-cp313-win_amd64.whl (40.6 MB)
Using cached numpy-2.2.6-cp313-cp313-win_amd64.whl (12.6 MB)
Using cached onnx-1.20.0-cp312-abi3-win_amd64.whl (16.5 MB)
Using cached pyyaml-6.0.3-cp313-cp313-win_amd64.whl (154 kB)
Using cached kaldi_native_fbank-1.22.3-cp313-cp313-win_amd64.whl (308 kB)
Using cached librosa-0.11.0-py3-none-any.whl (260 kB)
Using cached audioread-3.1.0-py3-none-any.whl (23 kB)
Using cached decorator-5.2.1-py3-none-any.whl (9.2 kB)
Using cached joblib-1.5.2-py3-none-any.whl (308 kB)
Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)
Using cached ml_dtypes-0.5.4-cp313-cp313-win_amd64.whl (212 kB)
Using cached msgpack-1.1.2-cp313-cp313-win_amd64.whl (72 kB)
Using cached numba-0.62.1-cp313-cp313-win_amd64.whl (2.7 MB)
Using cached llvmlite-0.45.1-cp313-cp313-win_amd64.whl (38.1 MB)
Using cached openvino_telemetry-2025.2.0-py3-none-any.whl (25 kB)
Using cached pooch-1.8.2-py3-none-any.whl (64 kB)
Using cached packaging-25.0-py3-none-any.whl (66 kB)
Using cached platformdirs-4.5.0-py3-none-any.whl (18 kB)
Using cached protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)
Using cached requests-2.32.5-py3-none-any.whl (64 kB)
Using cached charset_normalizer-3.4.4-cp313-cp313-win_amd64.whl (107 kB)
Using cached idna-3.11-py3-none-any.whl (71 kB)
Using cached urllib3-2.5.0-py3-none-any.whl (129 kB)
Using cached certifi-2025.11.12-py3-none-any.whl (159 kB)
Using cached scikit_learn-1.7.2-cp313-cp313-win_amd64.whl (8.7 MB)
Using cached scipy-1.16.3-cp313-cp313-win_amd64.whl (38.5 MB)
Using cached soundfile-0.13.1-py2.py3-none-win_amd64.whl (1.0 MB)
Using cached cffi-2.0.0-cp313-cp313-win_amd64.whl (183 kB)
Using cached soxr-1.0.0-cp312-abi3-win_amd64.whl (172 kB)
Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)
Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)
Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)
Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)
Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)
Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)
Using cached filelock-3.20.0-py3-none-any.whl (16 kB)
Using cached flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)
Using cached fsspec-2025.10.0-py3-none-any.whl (200 kB)
Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)
Using cached markupsafe-3.0.3-cp313-cp313-win_amd64.whl (15 kB)
Using cached networkx-3.6-py3-none-any.whl (2.1 MB)
Using cached pycparser-2.23-py3-none-any.whl (118 kB)
Using cached pyreadline3-3.5.4-py3-none-any.whl (83 kB)
Using cached setuptools-80.9.0-py3-none-any.whl (1.2 MB)
Using cached standard_aifc-3.13.0-py3-none-any.whl (10 kB)
Using cached audioop_lts-0.2.2-cp313-abi3-win_amd64.whl (30 kB)
Using cached standard_chunk-3.13.0-py3-none-any.whl (4.9 kB)
Using cached standard_sunau-3.13.0-py3-none-any.whl (7.4 kB)
Installing collected packages: standard-chunk, openvino-telemetry, mpmath, flatbuffers, urllib3, typing-extensions, threadpoolctl, sympy, setuptools, pyyaml, pyreadline3, pycparser, protobuf, platformdirs, packaging, numpy, networkx, msgpack, MarkupSafe, llvmlite, kaldi_native_fbank, joblib, idna, fsspec, filelock, decorator, charset_normalizer, certifi, audioop-lts, standard-sunau, standard-aifc, soxr, scipy, requests, openvino, numba, ml_dtypes, lazy_loader, jinja2, humanfriendly, cffi, torch, soundfile, scikit-learn, pooch, onnx, coloredlogs, audioread, onnxruntime-openvino, librosa
Successfully installed MarkupSafe-3.0.3 audioop-lts-0.2.2 audioread-3.1.0 certifi-2025.11.12 cffi-2.0.0 charset_normalizer-3.4.4 coloredlogs-15.0.1 decorator-5.2.1 filelock-3.20.0 flatbuffers-25.9.23 fsspec-2025.10.0 humanfriendly-10.0 idna-3.11 jinja2-3.1.6 joblib-1.5.2 kaldi_native_fbank-1.22.3 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.45.1 ml_dtypes-0.5.4 mpmath-1.3.0 msgpack-1.1.2 networkx-3.6 numba-0.62.1 numpy-2.2.6 onnx-1.20.0 onnxruntime-openvino-1.23.0 openvino-2025.3.0 openvino-telemetry-2025.2.0 packaging-25.0 platformdirs-4.5.0 pooch-1.8.2 protobuf-6.33.1 pycparser-2.23 pyreadline3-3.5.4 pyyaml-6.0.3 requests-2.32.5 scikit-learn-1.7.2 scipy-1.16.3 setuptools-80.9.0 soundfile-0.13.1 soxr-1.0.0 standard-aifc-3.13.0 standard-chunk-3.13.0 standard-sunau-3.13.0 sympy-1.14.0 threadpoolctl-3.6.0 torch-2.8.0 typing-extensions-4.15.0 urllib3-2.5.0

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>pip list
Package              Version    Build
-------------------- ---------- -----
audioop-lts          0.2.2
audioread            3.1.0
certifi              2025.11.12
cffi                 2.0.0
charset-normalizer   3.4.4
coloredlogs          15.0.1
decorator            5.2.1
filelock             3.20.0
flatbuffers          25.9.23
fsspec               2025.10.0
humanfriendly        10.0
idna                 3.11
Jinja2               3.1.6
joblib               1.5.2
kaldi-native-fbank   1.22.3
lazy_loader          0.4
librosa              0.11.0
llvmlite             0.45.1
MarkupSafe           3.0.3
ml_dtypes            0.5.4
mpmath               1.3.0
msgpack              1.1.2
networkx             3.6
numba                0.62.1
numpy                2.2.6
onnx                 1.20.0
onnxruntime-openvino 1.23.0
openvino             2025.3.0   19807
openvino-telemetry   2025.2.0
packaging            25.0
pip                  25.3
platformdirs         4.5.0
pooch                1.8.2
protobuf             6.33.1
pycparser            2.23
pyreadline3          3.5.4
PyYAML               6.0.3
requests             2.32.5
scikit-learn         1.7.2
scipy                1.16.3
setuptools           80.9.0
soundfile            0.13.1
soxr                 1.0.0
standard-aifc        3.13.0
standard-chunk       3.13.0
standard-sunau       3.13.0
sympy                1.14.0
threadpoolctl        3.6.0
torch                2.8.0
typing_extensions    4.15.0
urllib3              2.5.0

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python export_encoder_onnx.py --input-len-in-seconds 5
{'input_len_in_seconds': 5}
loading model
creating model
loading state dict
num_frames 500
num_input_frames 83
C:\Github\paraformer-zh-ovep-python-static\export_encoder_onnx.py:160: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.
  torch.onnx.export(
in xs_pad.shape torch.Size([1, 83, 560])
out xs_pad.shape torch.Size([1, 83, 512])
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\_internal\jit_utils.py:309: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\utils.py:684: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_graph_shape_type_inference(
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\utils.py:1154: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_graph_shape_type_inference(
Saved to encoder-5-seconds.onnx

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python export_decoder_onnx.py --input-len-in-seconds 5
loading model
creating model
loading state dict
num_frames 500
num_input_frames 83
hidden torch.Size([1, 83, 512])
self.output_layer Linear(in_features=512, out_features=8404, bias=True)
x torch.Size([1, 83, 8404])
d torch.Size([1, 83, 8404])
C:\Github\paraformer-zh-ovep-python-static\export_decoder_onnx.py:28: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.
  torch.onnx.export(
hidden torch.Size([1, 83, 512])
self.output_layer Linear(in_features=512, out_features=8404, bias=True)
x torch.Size([1, 83, 8404])
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\_internal\jit_utils.py:309: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\utils.py:684: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_graph_shape_type_inference(
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\utils.py:1154: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_graph_shape_type_inference(
Saved to decoder-5-seconds.onnx

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python export_predictor_onnx.py --input-len-in-seconds 5
loading model
creating model
loading state dict
num_frames 500
num_input_frames 83
C:\Github\paraformer-zh-ovep-python-static\export_predictor_onnx.py:45: DeprecationWarning: You are using the legacy TorchScript-based ONNX export. Starting in PyTorch 2.9, the new torch.export-based ONNX exporter will be the default. To switch now, set dynamo=True in torch.onnx.export. This new exporter supports features like exporting LLMs with DynamicCache. We encourage you to try it and share feedback to help improve the experience. Learn more about the new export logic: https://pytorch.org/docs/stable/onnx_dynamo.html. For exporting control flow: https://pytorch.org/tutorials/beginner/onnx/export_control_flow_model_to_onnx_tutorial.html.
  torch.onnx.export(
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\_internal\jit_utils.py:309: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_node_shape_type_inference(node, params_dict, opset_version)
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\utils.py:684: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_graph_shape_type_inference(
C:\Python\openvino_venv\Lib\site-packages\torch\onnx\utils.py:1154: UserWarning: Constant folding - Only steps=1 can be constant folded for opset >= 10 onnx::Slice op. Constant folding not applied. (Triggered internally at C:\actions-runner\_work\pytorch\pytorch\pytorch\torch\csrc\jit\passes\onnx\constant_fold.cpp:180.)
  _C._jit_pass_onnx_graph_shape_type_inference(
Saved to predictor-5-seconds.onnx

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>dir
 Volume in drive C is InstallTo
 Volume Serial Number is 76DF-BB22

 Directory of C:\Github\paraformer-zh-ovep-python-static

11/21/2025  11:51 AM    <DIR>          .
11/20/2025  04:20 PM    <DIR>          ..
11/21/2025  11:32 AM           179,712 0.wav
11/21/2025  11:32 AM           165,042 1.wav
11/21/2025  11:32 AM           144,922 2.wav
11/21/2025  11:44 AM            11,203 am.mvn
11/21/2025  11:44 AM             2,509 config.yaml
11/21/2025  11:44 AM               472 configuration.json
11/21/2025  11:50 AM       228,460,151 decoder-5-seconds.onnx
11/21/2025  11:50 AM       632,885,122 encoder-5-seconds.onnx
11/21/2025  11:32 AM             1,169 export_decoder_onnx.py
11/21/2025  11:32 AM             5,189 export_encoder_onnx.py
11/21/2025  11:32 AM             1,510 export_predictor_onnx.py
11/21/2025  11:45 AM       880,502,012 model.pt
11/21/2025  11:51 AM         3,152,772 predictor-5-seconds.onnx
11/21/2025  11:32 AM             6,446 README.md
11/21/2025  11:32 AM               120 requirements.txt
11/21/2025  11:45 AM         8,287,834 seg_dict
11/21/2025  11:32 AM            10,969 test_onnx.py
11/21/2025  11:45 AM            93,676 tokens.json
11/21/2025  11:32 AM            44,688 torch_model.py
11/21/2025  11:50 AM    <DIR>          __pycache__
              19 File(s)  1,753,955,518 bytes
               3 Dir(s)  225,971,204,096 bytes free

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python test_onnx.py --input-len-in-seconds 5 1.wav
num_frames 500
num_input_frames 83
features sum 612931.0 (516, 80)
here (85, 560) True
features.shape (83, 560) (83, 560)
sum 700035.94 15.061014 17006.455 0.36588758
Device: Using Default CPU Executor.
init encoder: ./encoder-5-seconds.onnx
init decoder: ./decoder-5-seconds.onnx
init predictor: ./predictor-5-seconds.onnx
---encoder---
NodeArg(name='x', type='tensor(float)', shape=[1, 83, 560])
-----
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
---decoder---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='acoustic_embedding', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='mask', type='tensor(float)', shape=[83])
-----
NodeArg(name='decoder_out', type='tensor(float)', shape=[1, 83, 8404])
---predictor---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
-----
NodeArg(name='alphas', type='tensor(float)', shape=[1, 83])
encoder_out.shape (1, 83, 512)
encoder_out.sum 64.54709 0.001518898
alpha.shape (1, 83)
alpha.sum() 26.999685 0.32529742
acoustic_embedding.shape (26, 512)
padding.shape (57, 512) (26, 512)
acoustic_embedding.shape (83, 512)
acoustic_embedding.sum 17.4013 0.0004094809
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
decoder_out encoder_out acoustic_embedding
decoder_out (1, 83, 8404)
decoder_out.sum 471091.5 0.675369
[3055, 278, 7404, 6801, 3806, 1680, 6184, 4390, 1409, 7827, 7118, 7404, 991, 6426, 4803, 1074, 2773, 3595, 8069, 2483, 1320, 1980, 6857, 4500, 1383, 2] --> 26
['重', '点', '呢', '想', '谈', '三', '个', '问', '题', '首', '先', '呢', '就', '是', '这', '一', '轮', '全', '球', '金', '融', '动', '荡', '表', '现']
重点呢想谈三个问题首先呢就是这一轮全球金融动荡表现

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python test_onnx.py --device CPU --input-len-in-seconds 5 1.wav
num_frames 500
num_input_frames 83
features sum 612931.0 (516, 80)
here (85, 560) True
features.shape (83, 560) (83, 560)
sum 700035.94 15.061014 17006.455 0.36588758
Device: OpenVINO EP with device = CPU
init encoder: ./encoder-5-seconds.onnx
init decoder: ./decoder-5-seconds.onnx
init predictor: ./predictor-5-seconds.onnx
---encoder---
NodeArg(name='x', type='tensor(float)', shape=[1, 83, 560])
-----
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
---decoder---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='acoustic_embedding', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='mask', type='tensor(float)', shape=[83])
-----
NodeArg(name='decoder_out', type='tensor(float)', shape=[1, 83, 8404])
---predictor---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
-----
NodeArg(name='alphas', type='tensor(float)', shape=[1, 83])
encoder_out.shape (1, 83, 512)
encoder_out.sum 64.54708 0.0015188978
alpha.shape (1, 83)
alpha.sum() 26.999683 0.3252974
acoustic_embedding.shape (26, 512)
padding.shape (57, 512) (26, 512)
acoustic_embedding.shape (83, 512)
acoustic_embedding.sum 17.4013 0.0004094809
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
decoder_out encoder_out acoustic_embedding
decoder_out (1, 83, 8404)
decoder_out.sum 471092.0 0.67536974
[3055, 278, 7404, 6801, 3806, 1680, 6184, 4390, 1409, 7827, 7118, 7404, 991, 6426, 4803, 1074, 2773, 3595, 8069, 2483, 1320, 1980, 6857, 4500, 1383, 2] --> 26
['重', '点', '呢', '想', '谈', '三', '个', '问', '题', '首', '先', '呢', '就', '是', '这', '一', '轮', '全', '球', '金', '融', '动', '荡', '表', '现']
重点呢想谈三个问题首先呢就是这一轮全球金融动荡表现

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python test_onnx.py --device GPU --input-len-in-seconds 5 1.wav
num_frames 500
num_input_frames 83
features sum 612931.0 (516, 80)
here (85, 560) True
features.shape (83, 560) (83, 560)
sum 700035.94 15.061014 17006.455 0.36588758
Device: OpenVINO EP with device = GPU
init encoder: ./encoder-5-seconds.onnx
init decoder: ./decoder-5-seconds.onnx
init predictor: ./predictor-5-seconds.onnx
---encoder---
NodeArg(name='x', type='tensor(float)', shape=[1, 83, 560])
-----
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
---decoder---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='acoustic_embedding', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='mask', type='tensor(float)', shape=[83])
-----
NodeArg(name='decoder_out', type='tensor(float)', shape=[1, 83, 8404])
---predictor---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
-----
NodeArg(name='alphas', type='tensor(float)', shape=[1, 83])
encoder_out.shape (1, 83, 512)
encoder_out.sum 64.565575 0.001519333
alpha.shape (1, 83)
alpha.sum() 26.999971 0.32530087
acoustic_embedding.shape (26, 512)
padding.shape (57, 512) (26, 512)
acoustic_embedding.shape (83, 512)
acoustic_embedding.sum 17.398949 0.00040942556
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
decoder_out encoder_out acoustic_embedding
decoder_out (1, 83, 8404)
decoder_out.sum 471775.56 0.6763497
[3055, 278, 7404, 6801, 3806, 1680, 6184, 4390, 1409, 7827, 7118, 7404, 991, 6426, 4803, 1074, 2773, 3595, 8069, 2483, 1320, 1980, 6857, 4500, 1383, 2] --> 26
['重', '点', '呢', '想', '谈', '三', '个', '问', '题', '首', '先', '呢', '就', '是', '这', '一', '轮', '全', '球', '金', '融', '动', '荡', '表', '现']
重点呢想谈三个问题首先呢就是这一轮全球金融动荡表现

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>python test_onnx.py --device NPU --input-len-in-seconds 5 1.wav
num_frames 500
num_input_frames 83
features sum 612931.0 (516, 80)
here (85, 560) True
features.shape (83, 560) (83, 560)
sum 700035.94 15.061014 17006.455 0.36588758
Device: OpenVINO EP with device = NPU
init encoder: ./encoder-5-seconds.onnx
init decoder: ./decoder-5-seconds.onnx
init predictor: ./predictor-5-seconds.onnx
---encoder---
NodeArg(name='x', type='tensor(float)', shape=[1, 83, 560])
-----
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
---decoder---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='acoustic_embedding', type='tensor(float)', shape=[1, 83, 512])
NodeArg(name='mask', type='tensor(float)', shape=[83])
-----
NodeArg(name='decoder_out', type='tensor(float)', shape=[1, 83, 8404])
---predictor---
NodeArg(name='encoder_out', type='tensor(float)', shape=[1, 83, 512])
-----
NodeArg(name='alphas', type='tensor(float)', shape=[1, 83])
encoder_out.shape (1, 83, 512)
encoder_out.sum 64.594604 0.0015200161
alpha.shape (1, 83)
alpha.sum() 26.999882 0.32529977
acoustic_embedding.shape (26, 512)
padding.shape (57, 512) (26, 512)
acoustic_embedding.shape (83, 512)
acoustic_embedding.sum 17.41497 0.00040980257
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
decoder_out encoder_out acoustic_embedding
decoder_out (1, 83, 8404)
decoder_out.sum 459326.0 0.6585017
[3055, 278, 7404, 6801, 3806, 1680, 6184, 4390, 1409, 7827, 7118, 7404, 991, 6426, 4803, 1074, 2773, 3595, 8069, 2483, 1320, 1980, 6857, 4500, 1383, 2] --> 26
['重', '点', '呢', '想', '谈', '三', '个', '问', '题', '首', '先', '呢', '就', '是', '这', '一', '轮', '全', '球', '金', '融', '动', '荡', '表', '现']
重点呢想谈三个问题首先呢就是这一轮全球金融动荡表现

(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
(openvino_venv) C:\Github\paraformer-zh-ovep-python-static>
